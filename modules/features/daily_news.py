import httpx
from bs4 import BeautifulSoup
from modules.nlp.openai_utils import summarize_with_gpt

async def get_daily_news(limit: int = 3) -> str:
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏î‡πà‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏à‡∏≤‡∏Å Google News RSS (TH) ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏î‡πâ‡∏ß‡∏¢ GPT ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠
    """
    url = "https://news.google.com/rss?hl=th&gl=TH&ceid=TH:th"
    try:
        async with httpx.AsyncClient() as client:
            res = await client.get(url, timeout=10)
            res.raise_for_status()
            soup = BeautifulSoup(res.text, "xml")

            items = soup.find_all("item", limit=limit)
            if not items:
                return "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ"

            summarized_news = []

            for item in items:
                title = item.title.text.strip()
                link = item.link.text.strip() if item.link else ""
                raw_desc = item.description.text if item.description else ""
                clean_desc = BeautifulSoup(raw_desc, "html.parser").get_text()

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÉ‡∏´‡πâ GPT
                full_text = f"{title}\n{clean_desc}"
                summary = await summarize_with_gpt(full_text)

                news_block = f"üì∞ {summary}"
                if link:
                    news_block += f"\nüîó [‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≠](<{link}>)"

                summarized_news.append(news_block)

            return "üóûÔ∏è ‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏î‡πà‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô:\n\n" + "\n\n".join(summarized_news)

    except Exception as e:
        return f"‚ùå ‡∏û‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ({e})"
